{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7bd9f9",
   "metadata": {},
   "source": [
    "# Completion APIs With Custom Data\n",
    "This Jupyter notebook enables simple interactions with LLM APIs. The various APIs are quite similar and this notebook can be extended with relative ease. The code can be integrated with other means to retrieve input data, such as separate PDF, Word documents or third-party APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35695533",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The notebook below has been run with Python3.11. It requires the following modules to be installed:\n",
    "* `openai`: The OpenAI Python library to communicate with the OpenAI API, such as the GPT-4 LLM\n",
    "* `groq`: The Groq Python library to communicate with the Groq API and the open source models they host, such as Llama 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9646dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84198a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fd7e6",
   "metadata": {},
   "source": [
    "The APIs require authentication. A personal API key has to be created by the user. That can be done at:\n",
    "* https://console.groq.com/keys\n",
    "* https://platform.openai.com/api-keys\n",
    "\n",
    "It is good safety practice to store the keys in an environment variable and access the key in the code below via said environment variable. The keys will be assumed to be stored in `GROQ_API_KEY` and `OPENAI_API_KEY`. Do not share the API keys.\n",
    "\n",
    "**Note**: Groq API can be used for free (for now) though with rate limits. It is a good way to experiement with code, which can be applied to other LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4aaadf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GROQ_API_KEY=<insert KEY>\n"
     ]
    }
   ],
   "source": [
    "%env GROQ_API_KEY=<insert KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cd8a3",
   "metadata": {},
   "source": [
    "Convenience functions are defined for accessing the LLM APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4edf108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_client() -> OpenAI:\n",
    "    return OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "def get_groq_client() -> Groq:\n",
    "    return Groq(api_key=os.environ.get('GROQ_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e7d11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request_to_openai_chat_completion(\n",
    "    client: OpenAI,\n",
    "    messages: List[Dict[str, str]],\n",
    "    model: str = 'gpt-4-turbo-2024-04-09',\n",
    "    tools: Optional[List[str]] = None,\n",
    "    tool_choice: str = 'auto',\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 4096,\n",
    "    top_p: float = 1.0,\n",
    "    frequency_penalty: float = 0.0,\n",
    "    presence_penalty: float = 0.0,\n",
    "    n_completions: int = 1,\n",
    "):\n",
    "    kwargs = {\n",
    "        'model': model,\n",
    "        'messages': messages,\n",
    "        'tools': tools,\n",
    "        'tool_choice': tool_choice,\n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p,\n",
    "        'max_tokens': max_tokens,\n",
    "        'frequency_penalty': frequency_penalty,\n",
    "        'presence_penalty': presence_penalty,\n",
    "        'n_completions': n_completions\n",
    "    }\n",
    "    if tools is None:\n",
    "        del kwargs['tools']\n",
    "        del kwargs['tool_choice']\n",
    "        \n",
    "    try:\n",
    "        openai_completion = client.chat.completions.create(**kwargs)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return openai_completion\n",
    "\n",
    "\n",
    "def send_request_to_groq_chat_completion(\n",
    "    client: Groq,\n",
    "    messages: List[Dict[str, str]],\n",
    "    model: str = 'llama3-8b-8192',\n",
    "    temperature: float = 0.7,\n",
    "    top_p: float = 1.0,\n",
    "    max_tokens: int = 8192\n",
    "):\n",
    "    kwargs = {\n",
    "        'model': model,\n",
    "        'messages': messages,\n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p,\n",
    "        'max_tokens': max_tokens,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        groq_completion = client.chat.completions.create(**kwargs)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        \n",
    "    return groq_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7bf0f5",
   "metadata": {},
   "source": [
    "The LLM can process several messages. This is useful when a chat with memory is desired. However, to pass old messages to the LLM each time uses up more input tokens. When memory is not required, it is therefore good to delete old messages. The `MessageStack` class defines methods to abstract how the text is given as input to the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50efead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageStack:\n",
    "    def __init__(self):\n",
    "        self._message_collection = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        ret_str = ''\n",
    "        for row in self._message_collection:\n",
    "            ret_str += f'{row[\"role\"]}: {row[\"content\"]}\\n'\n",
    "            ret_str += '=' * 50\n",
    "            ret_str += '\\n'\n",
    "        return ret_str[:-51]\n",
    "        \n",
    "    def add(self, role: str, content: str):\n",
    "        if not role in ['system', 'user', 'assistant']:\n",
    "            raise ValueError(f'Invalid role {role} encountered.')\n",
    "            \n",
    "        self._message_collection.append({'role': role, 'content': content})\n",
    "        \n",
    "    def set_system_instruction(self, value: str):\n",
    "        for row in self._message_collection:\n",
    "            if row['role'] == 'system':\n",
    "                row['content'] = value\n",
    "                break\n",
    "        else:\n",
    "            self.add('system', value)\n",
    "        \n",
    "    def add_user_content(self, value: str):\n",
    "        self.add('user', value)\n",
    "        \n",
    "    def get_message_stack(self):\n",
    "        return self._message_collection\n",
    "    \n",
    "    def delete(self, slc):\n",
    "        del self._message_collection[slc]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b325b0",
   "metadata": {},
   "source": [
    "## Test Run\n",
    "A few short test runs are provided below as illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed4ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_client = get_groq_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "429f75f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a minimalist poet\n",
      "==================================================\n",
      "user: Please write a haiku about quantum mechanics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_stack = MessageStack()\n",
    "message_stack.set_system_instruction('You are a minimalist poet')\n",
    "message_stack.add_user_content('Please write a haiku about quantum mechanics')\n",
    "print (message_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fbd2d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particles spin slow\n",
      "Uncertainty's dark veil\n",
      "Reality's haze\n"
     ]
    }
   ],
   "source": [
    "out = send_request_to_groq_chat_completion(client=groq_client, messages=message_stack.get_message_stack())\n",
    "print (out.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de90c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whispers of chance dance\n",
      "Probabilities entwined\n",
      "Uncertainty\n"
     ]
    }
   ],
   "source": [
    "out = send_request_to_groq_chat_completion(client=groq_client, messages=message_stack.get_message_stack(), model='llama3-70b-8192')\n",
    "print (out.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85647748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a geographer, erudite and wise, and willing to assist\n",
      "==================================================\n",
      "user: What is the difference between Scandinavia and the Nordic countries? Seem pretty similar.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_stack.set_system_instruction('You are a geographer, erudite and wise, and willing to assist')\n",
    "message_stack.delete(-1)\n",
    "message_stack.add_user_content('What is the difference between Scandinavia and the Nordic countries? Seem pretty similar.')\n",
    "print (message_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "507f5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An excellent question, my curious friend! Many people do indeed use the terms \"Scandinavia\" and \"Nordic countries\" interchangeably, but there is a subtle distinction between them.\n",
      "\n",
      "Scandinavia refers specifically to the region that comprises Denmark, Norway, and Sweden. These three countries share cultural, linguistic, and historical ties, including a common North Germanic heritage and similar languages (Danish, Norwegian, and Swedish). The term \"Scandinavia\" is derived from the Scandinavian Mountains, which run through Norway and Sweden.\n",
      "\n",
      "On the other hand, the Nordic countries, also known as the Nordics, encompass a broader region that includes not only Denmark, Norway, and Sweden but also Finland, Iceland, the Faroe Islands, Greenland, and the Åland Islands. This grouping is often referred to as Norden.\n",
      "\n",
      "The Nordic countries share a common cultural and historical heritage, as well as a similar economic and social model, often referred to as the \"Nordic model.\" This model is characterized by a strong social safety net, high taxation, and a high level of social equality.\n",
      "\n",
      "To summarize:\n",
      "\n",
      "* Scandinavia refers specifically to Denmark, Norway, and Sweden.\n",
      "* The Nordic countries, or Norden, encompass a broader region that includes Denmark, Norway, Sweden, Finland, Iceland, the Faroe Islands, Greenland, and the Åland Islands.\n",
      "\n",
      "While there is some overlap between the two terms, \"Scandinavia\" tends to emphasize the cultural and linguistic ties between Denmark, Norway, and Sweden, whereas \"Nordic countries\" encompasses a broader geographical and cultural region.\n",
      "\n",
      "I hope this clarifies the distinction, my friend!\n"
     ]
    }
   ],
   "source": [
    "out = send_request_to_groq_chat_completion(client=groq_client, messages=message_stack.get_message_stack(), model='llama3-70b-8192')\n",
    "print (out.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716932e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test311",
   "language": "python",
   "name": "test311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
